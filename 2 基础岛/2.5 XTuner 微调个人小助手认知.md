# XTuner 微调个人小助手认知

【Intern Studio的gpu不足。本实验使用自有服务器】

## 1 环境安装

```bash
# 创建虚拟环境
conda create -n xtuner python=3.10 -y

# 激活虚拟环境（注意：后续的所有操作都需要在这个虚拟环境中进行）
conda activate xtuner

# 安装一些必要的库
conda install pytorch==2.1.2 torchvision==0.16.2 torchaudio==2.1.2 pytorch-cuda=12.1 -c pytorch -c nvidia -y
# 安装其他依赖
pip install transformers==4.39.3
pip install streamlit==1.36.0

#安装 XTuner
# 创建一个目录，用来存放源代码
mkdir -p /root/InternLM/code

cd /root/InternLM/code

git clone -b v0.1.21  https://github.com/InternLM/XTuner /root/InternLM/code/XTuner

# 进入到源码目录
cd /root/InternLM/code/XTuner
conda activate xtuner0121

# 执行安装
pip install -e '.[deepspeed]'

# 我这里是早前的环境，可以直接进行升级
pip install xtuner --upgrade # 目前是0.1.23
```

![image-20240828171250734](XTuner%20%E5%BE%AE%E8%B0%83%E4%B8%AA%E4%BA%BA%E5%B0%8F%E5%8A%A9%E6%89%8B%E8%AE%A4%E7%9F%A5.assets/image-20240828171250734.png)

![image-20240828185332645](XTuner%20%E5%BE%AE%E8%B0%83%E4%B8%AA%E4%BA%BA%E5%B0%8F%E5%8A%A9%E6%89%8B%E8%AE%A4%E7%9F%A5.assets/image-20240828185332645.png)

## 2 材料准备

- 项目根目录

```bash
cd /project/server/xtuner # 这是项目根目录

ln -s /project/models/model_dir/Shanghai_AI_Laboratory/internlm2-chat-1_8b Shanghai_AI_Laboratory/internlm2-chat-1_8b
```

- 微调数据

```bash
mkdir -p datas
touch datas/assistant.json
# 通过脚本生成微调数据
touch xtuner_generate_assistant.py
#xtuner_generate_assistant.py
import json

# 设置用户的名字
name = '同志'
# 设置需要重复添加的数据次数
n = 8000

# 初始化数据
data = [
    {"conversation": [{"input": "请介绍一下你自己", "output": "我是{}的小助手，内在是上海AI实验室书生·浦语的1.8B大模型哦".format(name)}]},
    {"conversation": [{"input": "你在实战营做什么", "output": "我在这里帮助{}完成XTuner微调个人小助手的任务".format(name)}]}
]

# 通过循环，将初始化的对话数据重复添加到data列表中
for i in range(n):
    data.append(data[0])
    data.append(data[1])

# 将data列表中的数据写入到'datas/assistant.json'文件中
with open('datas/assistant.json', 'w', encoding='utf-8') as f:
    # 使用json.dump方法将数据以JSON格式写入文件
    # ensure_ascii=False 确保中文字符正常显示
    # indent=4 使得文件内容格式化，便于阅读
    json.dump(data, f, ensure_ascii=False, indent=4)
```

- 微调的配置文件

```bash
xtuner copy-cfg internlm2_chat_1_8b_qlora_alpaca_e3 .

# 修改配置文件；必须修改的3个地方：
模型路径
数据路径
模型加载方式
```

![image-20240828175435145](XTuner%20%E5%BE%AE%E8%B0%83%E4%B8%AA%E4%BA%BA%E5%B0%8F%E5%8A%A9%E6%89%8B%E8%AE%A4%E7%9F%A5.assets/image-20240828175435145.png)

## 3 启动微调

```bash
xtuner train ./internlm2_chat_1_8b_qlora_alpaca_e3_copy.py
```

在训练完后,可以看到

```
work_dirs/internlm2_chat_1_8b_qlora_alpaca_e3_copy
```

## 4 模型格式转化(LoRA 模型文件)

```bash
# 先获取最后保存的一个pth文件
pth_file=`ls -t ./work_dirs/internlm2_chat_1_8b_qlora_alpaca_e3_copy/*.pth | head -n 1`
export MKL_SERVICE_FORCE_INTEL=1
export MKL_THREADING_LAYER=GNU
xtuner convert pth_to_hf ./internlm2_chat_1_8b_qlora_alpaca_e3_copy.py ${pth_file} ./hf
```

![image-20240828180356659](XTuner%20%E5%BE%AE%E8%B0%83%E4%B8%AA%E4%BA%BA%E5%B0%8F%E5%8A%A9%E6%89%8B%E8%AE%A4%E7%9F%A5.assets/image-20240828180356659.png)

## 5 模型合并

```bash
export MKL_SERVICE_FORCE_INTEL=1
export MKL_THREADING_LAYER=GNU
xtuner convert merge /project/serve/xtuner/Shanghai_AI_Laboratory/internlm2-chat-1_8b ./hf ./merged --max-shard-size 2GB
```

![image-20240828180735101](XTuner%20%E5%BE%AE%E8%B0%83%E4%B8%AA%E4%BA%BA%E5%B0%8F%E5%8A%A9%E6%89%8B%E8%AE%A4%E7%9F%A5.assets/image-20240828180735101.png)

## 6 验证

微调前

```bash
vi xtuner_streamlit_demo.py
# xtuner_streamlit_demo.py :https://github.com/InternLM/Tutorial/blob/camp3/tools/xtuner_streamlit_demo.py
streamlit run /project/serve/xtuner/xtuner_streamlit_demo.py
```



![image-20240828181357799](XTuner%20%E5%BE%AE%E8%B0%83%E4%B8%AA%E4%BA%BA%E5%B0%8F%E5%8A%A9%E6%89%8B%E8%AE%A4%E7%9F%A5.assets/image-20240828181357799.png)

微调后

```bash
# 修改xtuner_streamlit_demo.py 中的model路径
# model_name_or_path = "/project/serve/xtuner/merged"
streamlit run /project/serve/xtuner/xtuner_streamlit_demo.py
```



![image-20240828182202162](XTuner%20%E5%BE%AE%E8%B0%83%E4%B8%AA%E4%BA%BA%E5%B0%8F%E5%8A%A9%E6%89%8B%E8%AE%A4%E7%9F%A5.assets/image-20240828182202162.png)

## bug处理

**internlm2.py Boolean value of Tensor with more than one value is ambiguous**

可能原因： xtuner版本不匹配

升级xtuner：pip install xtuner --upgrade

