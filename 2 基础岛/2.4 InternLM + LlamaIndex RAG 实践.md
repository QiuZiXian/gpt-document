# InternLM + LlamaIndex RAG 实践

【Intern Studio的gpu不足。本实验使用自有服务器】

## 1 环境安装

```bash
conda create -n llamaindex python=3.10
conda activate llamaindex
conda install pytorch==2.0.1 torchvision==0.15.2 torchaudio==2.0.2 pytorch-cuda=11.7 -c pytorch -c nvidia
pip install einops==0.7.0 protobuf==5.26.1
conda activate llamaindex
pip install llama-index==0.10.38 llama-index-llms-huggingface==0.2.0 "transformers[torch]==4.41.1" "huggingface_hub[inference]==0.23.1" huggingface_hub==0.23.1 sentence-transformers==2.7.0 sentencepiece==0.2.0

#llama-index -rag相关
pip install llama-index-embeddings-huggingface==0.2.0 llama-index-embeddings-instructor==0.1.3
```

## 2 材料准备

- internlm2-chat-1_8b模型下载

```bash
from modelscope.hub.snapshot_download import snapshot_download
 
model_dir = snapshot_download('Shanghai_AI_Laboratory/internlm2-chat-1_8b', cache_dir='./model_dir', revision='master')
```

- embeding 模型下载

```bash
# embeding 模型下载；需要科学上网
cd /project
mkdir llamaindex_demo
mkdir model
cd /project/llamaindex_demo
touch download_hf.py

#download_hf.py
import os

# 设置环境变量
os.environ['HF_ENDPOINT'] = 'https://hf-mirror.com'

# 下载模型
os.system('huggingface-cli download --resume-download sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2 --local-dir /root/model/sentence-transformer')
```

- 开源Embedding配套nltk

```bash
cd /project/llamaindex_demo
git clone https://gitee.com/yzy0612/nltk_data.git  --branch gh-pages
cd nltk_data
mv packages/*  ./
cd tokenizers
unzip punkt.zip
cd ../taggers
unzip averaged_perceptron_tagger.zip
```

- 设置软链接（可选，目的是简化路径）

```bash
cd /project/model
ln -s /project/models/model_dir/Shanghai_AI_Laboratory/internlm2-chat-1_8b/ ./
```

- rag的知识库准备

```bash
cd /project/llamaindex_demo
mkdir data
cd data
git clone https://github.com/InternLM/xtuner.git
mv xtuner/README_zh-CN.md ./
```

- 使用gpt生成一些独一无二的知识

  **注：以下定义百度是没有的，是通过gpt生成的**

```bash
cd /project/llamaindex_demo
mkdir data2
cd data2
vi k.txt
#k.txt内容如下
布鲁鲁尔（v.）- 指一种奇特的行为，即在吃冰淇淋时用鼻子呼出咖啡香气。这种行为被认为是一种超凡的美食体验，能够唤醒沉睡的味蕾。

炫烤器（n.）- 一种极为罕见且令人兴奋的厨房用具，据传说，它能将食物瞬间变成光亮的炫彩状态。使用炫烤器烹饪的食物会散发出奇幻的色彩和迷人的香气，令人难以置信。

智能笑话机器人（n.）- 这是一个不同寻常的机器人，其唯一任务是制作让人捧腹大笑的笑话。智能笑话机器人具备人工智能技术，可以根据不同的情境和听众的喜好创造个性化的笑话。它是喜剧表演的终极替代品。

量子思维帽（n.）- 一种奇妙的头戴设备，据说它能够扩展人类思维的边界。穿戴量子思维帽后，个体可以在瞬间获得超越常人的洞察力和创造力，从而解决世界上最复杂的问题。

反引力水晶（n.）- 一种传说中的神奇水晶，据说能够产生反引力效应。这种水晶被认为是引力定律的完全逆转者，当放置在物体下方时，它可以使物体向上漂浮，并且不受重力的影响。
```



## 3 还原实验

```bash
cd /project/llamaindex_demo
touch llamaindex_internlm.py

#llamaindex_internlm.py
from llama_index.llms.huggingface import HuggingFaceLLM
from llama_index.core.llms import ChatMessage
llm = HuggingFaceLLM(
    model_name="/root/model/internlm2-chat-1_8b",
    tokenizer_name="/root/model/internlm2-chat-1_8b",
    model_kwargs={"trust_remote_code":True},
    tokenizer_kwargs={"trust_remote_code":True}
)

rsp = llm.chat(messages=[ChatMessage(content="xtuner是什么？")])
print(rsp)

```

- 运行代码
  python llamaindex_internlm.py

```bash
cd /project/llamaindex_demo
touch llamaindex_RAG.py
#  llamaindex_RAG.py
from llama_index.core import VectorStoreIndex, SimpleDirectoryReader, Settings

from llama_index.embeddings.huggingface import HuggingFaceEmbedding
from llama_index.llms.huggingface import HuggingFaceLLM

#初始化一个HuggingFaceEmbedding对象，用于将文本转换为向量表示
embed_model = HuggingFaceEmbedding(
#指定了一个预训练的sentence-transformer模型的路径
    model_name="/root/model/sentence-transformer"
)
#将创建的嵌入模型赋值给全局设置的embed_model属性，
#这样在后续的索引构建过程中就会使用这个模型。
Settings.embed_model = embed_model

llm = HuggingFaceLLM(
    model_name="/root/model/internlm2-chat-1_8b",
    tokenizer_name="/root/model/internlm2-chat-1_8b",
    model_kwargs={"trust_remote_code":True},
    tokenizer_kwargs={"trust_remote_code":True}
)
#设置全局的llm属性，这样在索引查询时会使用这个模型。
Settings.llm = llm

#从指定目录读取所有文档，并加载数据到内存中
documents = SimpleDirectoryReader("/root/llamaindex_demo/data").load_data()
#创建一个VectorStoreIndex，并使用之前加载的文档来构建索引。
# 此索引将文档转换为向量，并存储这些向量以便于快速检索。
index = VectorStoreIndex.from_documents(documents)
# 创建一个查询引擎，这个引擎可以接收查询并返回相关文档的响应。
query_engine = index.as_query_engine()
response = query_engine.query("xtuner是什么?")

print(response)
```

![image-20240828170150119](InternLM%20+%20LlamaIndex%20RAG%20%E5%AE%9E%E8%B7%B5.assets/image-20240828170150119.png)

![image-20240828170231532](InternLM%20+%20LlamaIndex%20RAG%20%E5%AE%9E%E8%B7%B5.assets/image-20240828170231532.png)

## 4 更换问题验证rag

```bash
cp llamaindex_internlm.py llamaindex_internlm2.py
cp llamaindex_RAG.py llamaindex_RAG2.py
```

- 修改问题为：**反引力水晶是什么？**

- 原始回答

```bash
python llamaindex_internlm2.py
```

![image-20240828170600794](InternLM%20+%20LlamaIndex%20RAG%20%E5%AE%9E%E8%B7%B5.assets/image-20240828170600794.png)

- 结合知识库的rag回答

```bash
python llamaindex_internlm2.py
```

![image-20240828170634113](InternLM%20+%20LlamaIndex%20RAG%20%E5%AE%9E%E8%B7%B5.assets/image-20240828170634113.png)

和第一步中准备的知识库k.txt中的内容一致