茴香豆：企业级知识库问答工具

## 1 简介

[**茴香豆**](https://github.com/InternLM/HuixiangDou/) 是由书生·浦语团队开发的一款开源、专门针对国内企业级使用场景设计并优化的知识问答工具。在基础 RAG 课程中我们了解到，RAG 可以有效的帮助提高 LLM 知识检索的相关性、实时性，同时避免 LLM 训练带来的巨大成本。在实际的生产和生活环境需求，对 RAG 系统的开发、部署和调优的挑战更大，如需要解决群应答、能够无关问题拒答、多渠道应答、更高的安全性挑战。因此，根据大量国内用户的实际需求，总结出了**三阶段Pipeline**的茴香豆知识问答助手架构，帮助企业级用户可以快速上手安装部署。

**茴香豆特点**：

- 三阶段 Pipeline （前处理、拒答、响应），提高相应准确率和安全性
- 打通微信和飞书群聊天，适合国内知识问答场景
- 支持各种硬件配置安装，安装部署限制条件少
- 适配性强，兼容多个 LLM 和 API
- 傻瓜操作，安装和配置方便

[![img](https://raw.githubusercontent.com/fzd9752/pic_img/main/imgs/Screenshot%202024-08-23%20at%2020.23.25.png)](https://raw.githubusercontent.com/fzd9752/pic_img/main/imgs/Screenshot 2024-08-23 at 20.23.25.png)

## 2 web版使用

![image-20240904144657793](%E8%8C%B4%E9%A6%99%E8%B1%86%EF%BC%9A%E4%BC%81%E4%B8%9A%E7%BA%A7%E7%9F%A5%E8%AF%86%E5%BA%93%E9%97%AE%E7%AD%94%E5%B7%A5%E5%85%B7.assets/image-20240904144657793.png)

## 3 本地版搭建

### 3.1 环境安装

【30%开发机】

**PS：注意要在conda的base环境执行**

```bash
studio-conda -o internlm-base -t huixiangdou
```

**PS: 1个小时左右**

```bash
#创建成功，用下面的命令激活环境：
conda activate huixiangdou
```

### 3.2 模型准备

**PS:茴香豆默认会根据配置文件自动下载对应的模型文件，为了节省时间，我们科使用已有的模型，只需要在配置文件中设置相应路径即可。**

```bash
# 创建模型文件夹
cd /root && mkdir models

# 复制BCE模型
ln -s /root/share/new_models/maidalun1020/bce-embedding-base_v1 /root/models/bce-embedding-base_v1
ln -s /root/share/new_models/maidalun1020/bce-reranker-base_v1 /root/models/bce-reranker-base_v1

# 复制大模型参数（下面的模型，根据作业进度和任务进行**选择一个**就行）
ln -s /root/share/new_models/Shanghai_AI_Laboratory/internlm2-chat-7b /root/models/internlm2-chat-7b
```

3.3 安装茴香豆

#### 下载源码

```bash
cd /root
# 克隆代码仓库
git clone https://github.com/internlm/huixiangdou && cd huixiangdou
git checkout 79fa810
```

#### 安装依赖

**PS: BCEmbedding==0.1.5是正解，官方教程版本BCEmbedding==0.15有误**

```bash
conda activate huixiangdou
# parsing `word` format requirements
apt update
apt install python-dev libxml2-dev libxslt1-dev antiword unrtf poppler-utils pstotext tesseract-ocr flac ffmpeg lame libmad0 libsox-fmt-mp3 sox libjpeg-dev swig libpulse-dev
# python requirements
pip install BCEmbedding==0.1.5 cmake==3.30.2 lit==18.1.8 sentencepiece==0.2.0 protobuf==5.27.3 accelerate==0.33.0
pip install -r requirements.txt
# python3.8 安装 faiss-gpu 而不是 faiss
```

### 3.3 修改配置

- 方法一：编辑器修改/root/huixiangdou/config.ini

![image-20240904140919959](%E8%8C%B4%E9%A6%99%E8%B1%86%EF%BC%9A%E4%BC%81%E4%B8%9A%E7%BA%A7%E7%9F%A5%E8%AF%86%E5%BA%93%E9%97%AE%E7%AD%94%E5%B7%A5%E5%85%B7.assets/image-20240904140919959.png)

- 方法二：sed命令

```bash
sed -i '9s#.*#embedding_model_path = "/root/models/bce-embedding-base_v1"#' /root/huixiangdou/config.ini
sed -i '15s#.*#reranker_model_path = "/root/models/bce-reranker-base_v1"#' /root/huixiangdou/config.ini
sed -i '43s#.*#local_llm_path = "/root/models/internlm2-chat-7b"#' /root/huixiangdou/config.ini
```

### 3.4 知识库创建

```bash
conda activate huixiangdou

cd /root/huixiangdou && mkdir repodir

git clone https://github.com/internlm/huixiangdou --depth=1 repodir/huixiangdou
git clone https://github.com/open-mmlab/mmpose    --depth=1 repodir/mmpose

# Save the features of repodir to workdir, and update the positive and negative example thresholds into `config.ini`
mkdir workdir
python3 -m huixiangdou.service.feature_store
```

**ps:需要注意的是，每次更新原始知识文档和正反例，都需要重新运行 `python3 -m huixiangdou.service.feature_store` 命令进行向量知识库的重新创建和应答阈值的更新。**

![image-20240904142001987](%E8%8C%B4%E9%A6%99%E8%B1%86%EF%BC%9A%E4%BC%81%E4%B8%9A%E7%BA%A7%E7%9F%A5%E8%AF%86%E5%BA%93%E9%97%AE%E7%AD%94%E5%B7%A5%E5%85%B7.assets/image-20240904142001987.png)

### 3.5 测试知识助手

#### 3.5.1 命令行运行

```bash
conda activate huixiangdou
cd /root/huixiangdou
python3 -m huixiangdou.main --standalone
```

![image-20240904142534906](%E8%8C%B4%E9%A6%99%E8%B1%86%EF%BC%9A%E4%BC%81%E4%B8%9A%E7%BA%A7%E7%9F%A5%E8%AF%86%E5%BA%93%E9%97%AE%E7%AD%94%E5%B7%A5%E5%85%B7.assets/image-20240904142534906.png)

#### 3.5.2 可视化界面

```bash
conda activate huixiangdou
cd /root/huixiangdou
python3 -m huixiangdou.gradio


# 本地
ssh -CNg -L 7860:127.0.0.1:7860 root@ssh.intern-ai.org.cn -p <你的ssh端口号>
```

**可视化界面问答展示**

- 问题一：答非所问

![image-20240904143019145](%E8%8C%B4%E9%A6%99%E8%B1%86%EF%BC%9A%E4%BC%81%E4%B8%9A%E7%BA%A7%E7%9F%A5%E8%AF%86%E5%BA%93%E9%97%AE%E7%AD%94%E5%B7%A5%E5%85%B7.assets/image-20240904143019145.png)

- 问题二：

![image-20240904143201286](%E8%8C%B4%E9%A6%99%E8%B1%86%EF%BC%9A%E4%BC%81%E4%B8%9A%E7%BA%A7%E7%9F%A5%E8%AF%86%E5%BA%93%E9%97%AE%E7%AD%94%E5%B7%A5%E5%85%B7.assets/image-20240904143201286.png)



### 3.6 集成飞书&微信群聊

环境要求有点“苛刻”。

- 飞书需要企业管理员审核

- 微信则对安卓、微信要求苛刻

  **安卓机测试，茴香豆崩溃**

![image-20240904143551345](%E8%8C%B4%E9%A6%99%E8%B1%86%EF%BC%9A%E4%BC%81%E4%B8%9A%E7%BA%A7%E7%9F%A5%E8%AF%86%E5%BA%93%E9%97%AE%E7%AD%94%E5%B7%A5%E5%85%B7.assets/image-20240904143551345.png)

![image-20240904143606377](%E8%8C%B4%E9%A6%99%E8%B1%86%EF%BC%9A%E4%BC%81%E4%B8%9A%E7%BA%A7%E7%9F%A5%E8%AF%86%E5%BA%93%E9%97%AE%E7%AD%94%E5%B7%A5%E5%85%B7.assets/image-20240904143606377.png)

## 4 高阶应用

### 4.1 开启网络搜索

对于本地知识库没有提到的问题或是实时性强的问题，可以开启茴香豆的网络搜索功能，结合网络的搜索结果，生成更可靠的回答。

开启网络搜索功能需要用到 **Serper** 提供的 API：

1. 登录 [Serper](https://serper.dev/) ，注册：
2. 进入 [Serper API](https://serper.dev/api-key) 界面，复制自己的 API-key：

3. 替换 `/huixiangdou/config.ini` 中的 ***${YOUR-API-KEY}*** 为自己的API-key：

```bash
[web_search]
check https://serper.dev/api-key to get a free API key
x_api_key = "${YOUR-API-KEY}"
domain_partial_order = ["openai.com", "pytorch.org", "readthedocs.io", "nvidia.com", "stackoverflow.com", "juejin.cn", "zhuanlan.zhihu.com", "www.cnblogs.com"]
save_dir = "logs/web_search_result"
```



**PS：需要科学上网**

![image-20240904150048979](%E8%8C%B4%E9%A6%99%E8%B1%86%EF%BC%9A%E4%BC%81%E4%B8%9A%E7%BA%A7%E7%9F%A5%E8%AF%86%E5%BA%93%E9%97%AE%E7%AD%94%E5%B7%A5%E5%85%B7.assets/image-20240904150048979.png)

### 4.2 远程模型

茴香豆中有 3 处调用了模型，分别是 嵌入模型（Embedding）、重排模型（Rerank）和 大语音模型（LLM）

#### 远程向量&重排序模型

**目前茴香豆只支持 siliconflow 中向量&重排 bce 模型的调用**

调用[硅基流动](https://siliconflow.cn/) 的 API。

#### 远程大模型

**PS: 如果同时开启 local 和 remote 模型，茴香豆将采用混合模型的方案，详见 [技术报告](https://arxiv.org/abs/2401.08772)，效果更好。**

- 开启

想要启用远端大语言模型，首先修改 `/huixiangdou/config.ini` 本地和远程LLM 开关：

```bash
enable_local = 0 # 关闭本地模型
enable_remote = 1 # 启用云端模型
```

- 修改配置

修改 `remote_` 相关配置，填写 API key、模型类型等参数，茴香豆支持 OpenAI 的 API格式调用。

### 4.3 多模态功能

最新的茴香豆支持了多模态的图文检索，启用该功能后，茴香豆可以解析上传的图片内容，并根据图片内容和文字提示词进行检索回答。

图文检索功能需要至少 10G 显存支持本地向量和重排模型运行，下面的示例使用的全部是本地模型，因此需要 40G 的显存。【开发机至少需要是50%】

#### 4.3.1 茴香豆环境

- 旧版本要更新
- 或者空环境直接下载最新

#### 4.3.2 安装多模态模型和依赖

- 下载模型

```bash
# 设置环境变量
export HF_ENDPOINT='https://hf-mirror.com' # 使用 huggingface 中国镜像加速下载，如果在国外，忽略此步骤

# 下载模型
## 模型文件较大，如果遇到下载报错，重新运行命令就好
huggingface-cli download BAAI/bge-m3 --local-dir /root/models/bge-m3
huggingface-cli download BAAI/bge-visualized --local-dir /root/models/bge-visualized
huggingface-cli download BAAI/bge-reranker-v2-minicpm-layerwise --local-dir /root/models/bge-reranker-v2-minicpm-layerwise

# 需要手动将视觉模型移动到 BGE-m3 文件夹下
mv /root/models/bge-visualized/Visualized_m3.pth /root/models/bge-m3/
```

- 安装依赖

```bash
conda activate huixiangdou
cd /root/

# 从官方 github 安装最新版
git clone https://github.com/FlagOpen/FlagEmbedding.git
cd FlagEmbedding
pip install  .

# 复制 FlagEmbedding 缺失的文件，注意 huixiangdou/lib/python3.10/site-packages 是教程开始设置的环境，如果个人有更改，需要根据自己的环境重新填入对应的地址
cp ~/FlagEmbedding/FlagEmbedding/visual/eva_clip/model_configs /root/.conda/envs/huixiangdou/lib/python3.10/site-packages/FlagEmbedding/visual/eva_clip/
cp ~/FlagEmbedding/FlagEmbedding/visual/eva_clip/bpe_simple_vocab_16e6.txt.gz /root/.conda/envs/huixiangdou/lib/python3.10/site-packages/FlagEmbedding/visual/eva_clip/

# 其他依赖包
pip install timm ftfy peft 
```

####  4.3.3修改配置文件

**PS: 7B模型应对多模态效果一般**

```bash
sed -i '6s#.*#embedding_model_path = "/root/models/bge-m3"#' /root/huixiangdou/config-multimodal.ini
sed -i '7s#.*#reranker_model_path = "/root/models/bge-reranker-v2-minicpm-layerwise"#' /root/huixiangdou/config-multimodal.ini

sed -i '31s#.*#local_llm_path = "/root/models/internlm2-chat-7b"#' /root/huixiangdou/config-multimodal.ini
sed -i '20s#.*#enable_local = 1#' /root/huixiangdou/config-multimodal.ini
sed -i '21s#.*#enable_remote = 0#' /root/huixiangdou/config-multimodal.ini

# 多模态向量知识库另开一个位置存储，和非多模态区分开
sed -i '8s#.*#work_dir = "workdir-multi"#' /root/huixiangdou/config-multimodal.ini
sed -i '61s#.*#enable_cr = 0#' /root/huixiangdou/config-multimodal.ini # 关闭指代消岐功能
```



#### 4.4.4建立多模态知识库

```bash
# 新的向量知识库文件夹
cd /root/huixiangdou/
mkdir workdir-multi

# 提取多模态向量知识库
python3 -m huixiangdou.service.feature_store --config_path config-multimodal.ini
```

#### 4.4.5测试

```bash
conda activate huixiangdou
cd /root/huixiangdou

python3 -m huixiangdou.gradio --config_path config-multimodal.ini
```

![image-20240904182209594](%E8%8C%B4%E9%A6%99%E8%B1%86%EF%BC%9A%E4%BC%81%E4%B8%9A%E7%BA%A7%E7%9F%A5%E8%AF%86%E5%BA%93%E9%97%AE%E7%AD%94%E5%B7%A5%E5%85%B7.assets/image-20240904182209594.png)

## 5 自行测试

### 5.1 不使用知识库和网络搜索

![image-20240904151136707](%E8%8C%B4%E9%A6%99%E8%B1%86%EF%BC%9A%E4%BC%81%E4%B8%9A%E7%BA%A7%E7%9F%A5%E8%AF%86%E5%BA%93%E9%97%AE%E7%AD%94%E5%B7%A5%E5%85%B7.assets/image-20240904151136707.png)

### 5.2 仅开启网络搜索

- 按4.1开启网络搜索
- 不需要重启3.5.2
- 页面上直接开启即可

**PS：茴香豆逻辑或模型存在重大问题**

是进行了搜索，但是后台进行了训练？

![image-20240904150711514](%E8%8C%B4%E9%A6%99%E8%B1%86%EF%BC%9A%E4%BC%81%E4%B8%9A%E7%BA%A7%E7%9F%A5%E8%AF%86%E5%BA%93%E9%97%AE%E7%AD%94%E5%B7%A5%E5%85%B7.assets/image-20240904150711514.png)

### 5.3 仅使用知识库

根据3.4 创建xtuner知识库

```bash
# 或者直接上传文件
#这里使用网络知识文件
cd /root/huixiangdou
git clone https://github.com/InternLM/xtuner.git --depth=1 repodir/xtuner

conda activate huixiangdou
# 30%的开发机gpu不够，要停止其它运行的服务（如3.5.2），再运行
python3 -m huixiangdou.service.feature_store
```

**可以看到，还是有效果的，只是中文问题，也有中文知识库，为啥用英文回复呢**

![image-20240904152132225](%E8%8C%B4%E9%A6%99%E8%B1%86%EF%BC%9A%E4%BC%81%E4%B8%9A%E7%BA%A7%E7%9F%A5%E8%AF%86%E5%BA%93%E9%97%AE%E7%AD%94%E5%B7%A5%E5%85%B7.assets/image-20240904152132225.png)